{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a6a94c-1052-4731-90a0-5f91db3dc180",
   "metadata": {},
   "source": [
    "# Concrete Strength Prediction Analysis\n",
    "\n",
    "In this analysis, we'll explore the prediction of concrete strength using neural networks. We'll cover the following parts:\n",
    "\n",
    "**Part A: Baseline Model**\n",
    "In this part, we'll build a baseline neural network model with one hidden layer and evaluate its performance.\n",
    "\n",
    "**Part B: Normalization and Comparison**\n",
    "In this part, we'll normalize the data and compare the mean squared errors with the baseline model.\n",
    "\n",
    "**Part C: Increase Epochs and Comparison**\n",
    "Here, we'll increase the number of training epochs and compare the mean squared errors with the previous steps.\n",
    "\n",
    "**Part D: Three Hidden Layers and Comparison**\n",
    "Finally, we'll use a neural network with three hidden layers and compare its performance to the previous models.\n",
    "\n",
    "## Analysis and Conclusion\n",
    "\n",
    "In this section, we'll analyze the results from each part and draw meaningful conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187c455f-59be-4b17-b27c-9ae1523bef11",
   "metadata": {},
   "source": [
    "## Import Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f02a9f-b212-4e57-9237-0cc169aa8b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb6002-62ed-46ff-9894-a409fa192ab9",
   "metadata": {},
   "source": [
    "## Part A: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eeb481d-e28a-4b11-86b3-00e3167299ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the csv file\n",
    "\n",
    "df = pd.read_csv('concrete_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac02568-5ec0-4d4c-b5ed-f6d4a3f1f367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the count of missing values for each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d77cc8-3b5d-4156-854a-f6b02b957a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop(columns=['Strength'])\n",
    "y = df['Strength']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cd8296-9ce1-4593-80fe-ce30c7cd7647",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 337us/step - loss: 44740.8672\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 258us/step - loss: 20451.8438\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 342us/step - loss: 8792.4033\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 283us/step - loss: 3645.0833\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 284us/step - loss: 1783.6434\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 273us/step - loss: 1195.2069\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 286us/step - loss: 1047.2086\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 261us/step - loss: 1002.0460\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 275us/step - loss: 969.2526\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 270us/step - loss: 936.1733\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 252us/step - loss: 905.9006\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 254us/step - loss: 877.0346\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 266us/step - loss: 847.2577\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 268us/step - loss: 817.6665\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 249us/step - loss: 790.7077\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 267us/step - loss: 762.7830\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 244us/step - loss: 736.9035\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 250us/step - loss: 710.9905\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 264us/step - loss: 685.2400\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 242us/step - loss: 660.3107\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 270us/step - loss: 637.7868\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 241us/step - loss: 615.0353\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 244us/step - loss: 594.5252\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 254us/step - loss: 574.5651\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 240us/step - loss: 555.7272\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 258us/step - loss: 539.4702\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 524.5057\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 980us/step - loss: 510.5041\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 311us/step - loss: 497.6159\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 266us/step - loss: 484.0949\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 255us/step - loss: 471.8459\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 253us/step - loss: 460.5310\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 258us/step - loss: 449.1967\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 244us/step - loss: 439.4496\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 252us/step - loss: 429.1128\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 240us/step - loss: 419.5660\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 240us/step - loss: 410.4744\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 258us/step - loss: 401.4395\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 253us/step - loss: 393.6107\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 249us/step - loss: 384.6910\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 261us/step - loss: 377.6207\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 251us/step - loss: 369.2267\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 256us/step - loss: 362.0524\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 254us/step - loss: 355.1575\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 249us/step - loss: 348.6356\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 270us/step - loss: 342.5079\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 258us/step - loss: 335.8515\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 264us/step - loss: 329.9353\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 248us/step - loss: 324.8863\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 240us/step - loss: 319.1130\n",
      "10/10 [==============================] - 0s 273us/step\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train, epochs=50)\n",
    "\n",
    "# Predict using the trained model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994f7228-efed-4135-8724-1d951cd4b9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************\n",
      "*     Mean Squared Error     *\n",
      "*                            *\n",
      "*        329.1592           *\n",
      "*                            *\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a formatted box for MSE output\n",
    "\n",
    "\n",
    "mse_box = f\"\"\"\n",
    "******************************\n",
    "*     Mean Squared Error     *\n",
    "*                            *\n",
    "*        {mse:.4f}           *\n",
    "*                            *\n",
    "******************************\n",
    "\"\"\"\n",
    "\n",
    "print(mse_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9e503c-5e70-4420-aec0-047093855a70",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 262us/step\n",
      "10/10 [==============================] - 0s 260us/step\n",
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 264us/step\n",
      "10/10 [==============================] - 0s 259us/step\n",
      "10/10 [==============================] - 0s 254us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 274us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 261us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 270us/step\n",
      "10/10 [==============================] - 0s 270us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 262us/step\n",
      "10/10 [==============================] - 0s 276us/step\n",
      "10/10 [==============================] - 0s 268us/step\n",
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 280us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 263us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 355us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 258us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 262us/step\n",
      "10/10 [==============================] - 0s 268us/step\n",
      "10/10 [==============================] - 0s 252us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 263us/step\n",
      "10/10 [==============================] - 0s 273us/step\n",
      "10/10 [==============================] - 0s 255us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 261us/step\n",
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 260us/step\n",
      "10/10 [==============================] - 0s 274us/step\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store MSE values\n",
    "mse_list = []\n",
    "\n",
    "# Repeat the process 50 times\n",
    "for _ in range(50):\n",
    "    X = df.drop(columns=['Strength'])\n",
    "    y = df['Strength']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)  # Set verbose=0 to suppress output\n",
    "    \n",
    "    # Train the model (suppress verbose output)\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the MSE value\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mse_list.append(mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed9bb56-d92f-4c15-bb2a-58c515d8b1c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  1     *\n",
      "    *                             *\n",
      "    *         98.0430            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  2     *\n",
      "    *                             *\n",
      "    *         2317.5540            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  3     *\n",
      "    *                             *\n",
      "    *         80.6004            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  4     *\n",
      "    *                             *\n",
      "    *         114.4262            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  5     *\n",
      "    *                             *\n",
      "    *         108.2871            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  6     *\n",
      "    *                             *\n",
      "    *         120.2598            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  7     *\n",
      "    *                             *\n",
      "    *         71.1665            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  8     *\n",
      "    *                             *\n",
      "    *         110.1660            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  9     *\n",
      "    *                             *\n",
      "    *         87.8915            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 10     *\n",
      "    *                             *\n",
      "    *         87.5501            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 11     *\n",
      "    *                             *\n",
      "    *         390.8479            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 12     *\n",
      "    *                             *\n",
      "    *         100.7564            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 13     *\n",
      "    *                             *\n",
      "    *         183.8923            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 14     *\n",
      "    *                             *\n",
      "    *         108.6583            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 15     *\n",
      "    *                             *\n",
      "    *         109.7314            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 16     *\n",
      "    *                             *\n",
      "    *         80.2989            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 17     *\n",
      "    *                             *\n",
      "    *         88.3552            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 18     *\n",
      "    *                             *\n",
      "    *         121.4334            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 19     *\n",
      "    *                             *\n",
      "    *         115.2813            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 20     *\n",
      "    *                             *\n",
      "    *         114.3312            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 21     *\n",
      "    *                             *\n",
      "    *         1454.6620            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 22     *\n",
      "    *                             *\n",
      "    *         82.8702            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 23     *\n",
      "    *                             *\n",
      "    *         391.1561            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 24     *\n",
      "    *                             *\n",
      "    *         126.9839            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 25     *\n",
      "    *                             *\n",
      "    *         124.8808            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 26     *\n",
      "    *                             *\n",
      "    *         136.8042            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 27     *\n",
      "    *                             *\n",
      "    *         69.8685            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 28     *\n",
      "    *                             *\n",
      "    *         118.2952            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 29     *\n",
      "    *                             *\n",
      "    *         107.4424            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 30     *\n",
      "    *                             *\n",
      "    *         112.0071            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 31     *\n",
      "    *                             *\n",
      "    *         204.1927            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 32     *\n",
      "    *                             *\n",
      "    *         90.9049            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 33     *\n",
      "    *                             *\n",
      "    *         110.6999            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 34     *\n",
      "    *                             *\n",
      "    *         255.4716            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 35     *\n",
      "    *                             *\n",
      "    *         114.7467            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 36     *\n",
      "    *                             *\n",
      "    *         125.1432            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 37     *\n",
      "    *                             *\n",
      "    *         117.2699            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 38     *\n",
      "    *                             *\n",
      "    *         131.2561            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 39     *\n",
      "    *                             *\n",
      "    *         81.0297            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 40     *\n",
      "    *                             *\n",
      "    *         149.7722            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 41     *\n",
      "    *                             *\n",
      "    *         122.3250            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 42     *\n",
      "    *                             *\n",
      "    *         78.6006            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 43     *\n",
      "    *                             *\n",
      "    *         50.6862            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 44     *\n",
      "    *                             *\n",
      "    *         122.1636            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 45     *\n",
      "    *                             *\n",
      "    *         288.9434            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 46     *\n",
      "    *                             *\n",
      "    *         97.2018            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 47     *\n",
      "    *                             *\n",
      "    *         110.3077            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 48     *\n",
      "    *                             *\n",
      "    *         110.0178            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 49     *\n",
      "    *                             *\n",
      "    *         179.2917            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 50     *\n",
      "    *                             *\n",
      "    *         68.1153            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print the list of MSE values for each iteration\n",
    "for i, mse in enumerate(mse_list):\n",
    "    mse_box = f\"\"\"\n",
    "    *******************************\n",
    "    *   Mean Squared Error {i+1:2d}     *\n",
    "    *                             *\n",
    "    *         {mse:.4f}            *\n",
    "    *                             *\n",
    "    *******************************\n",
    "    \"\"\"\n",
    "    print(mse_box)# Build and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda3f37d-cffa-4ccc-b289-d4c9c67a78e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Mean Squared Errors: 198.8528\n",
      "Standard Deviation of Mean Squared Errors: 361.5544\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of the MSE values\n",
    "mean_mse = np.mean(mse_list)\n",
    "std_mse = np.std(mse_list)\n",
    "\n",
    "# Report the mean and standard deviation\n",
    "print(f\"Mean of Mean Squared Errors: {mean_mse:.4f}\")\n",
    "print(f\"Standard Deviation of Mean Squared Errors: {std_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325a240-aa04-4a3a-9c8f-1c613ebc3526",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part B: Normalization and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0d3ce01-ad97-435f-9c37-fcb5f408b5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 272us/step\n",
      "Mean Squared Error (Before Normalization): 198.8528\n",
      "Mean Squared Error (After Normalization): 514.8816\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "# Predict using the trained model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse_normalized = mean_squared_error(y_test, predictions)\n",
    "\n",
    "# Compare the mean squared errors\n",
    "print(f\"Mean Squared Error (Before Normalization): {mean_mse:.4f}\")\n",
    "print(f\"Mean Squared Error (After Normalization): {mse_normalized:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1480172c-381d-4e8a-8e45-288f0c718b68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 268us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 264us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 259us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 276us/step\n",
      "10/10 [==============================] - 0s 253us/step\n",
      "10/10 [==============================] - 0s 259us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 274us/step\n",
      "10/10 [==============================] - 0s 264us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 286us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 263us/step\n",
      "10/10 [==============================] - 0s 264us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 259us/step\n",
      "10/10 [==============================] - 0s 261us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 278us/step\n",
      "10/10 [==============================] - 0s 260us/step\n",
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 276us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 264us/step\n",
      "10/10 [==============================] - 0s 286us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 257us/step\n",
      "10/10 [==============================] - 0s 256us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 262us/step\n",
      "10/10 [==============================] - 0s 263us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 273us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 264us/step\n",
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 276us/step\n",
      "10/10 [==============================] - 0s 258us/step\n",
      "10/10 [==============================] - 0s 274us/step\n",
      "10/10 [==============================] - 0s 271us/step\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store MSE values for normalized data\n",
    "normalized_mse_list = []\n",
    "\n",
    "# Repeat the process 50 times\n",
    "for _ in range(50):\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model (suppress verbose output)\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the MSE value\n",
    "    mse_normalized = mean_squared_error(y_test, predictions)\n",
    "    normalized_mse_list.append(mse_normalized)\n",
    "\n",
    "# Calculate the mean of the mean squared errors for normalized data\n",
    "mean_normalized_mse = np.mean(normalized_mse_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "474c3839-04c3-4769-90cd-399925af684d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  1     *\n",
      "    *                             *\n",
      "    *         243.5635            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  2     *\n",
      "    *                             *\n",
      "    *         454.7247            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  3     *\n",
      "    *                             *\n",
      "    *         354.8817            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  4     *\n",
      "    *                             *\n",
      "    *         296.6535            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  5     *\n",
      "    *                             *\n",
      "    *         335.7860            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  6     *\n",
      "    *                             *\n",
      "    *         355.9401            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  7     *\n",
      "    *                             *\n",
      "    *         310.9380            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  8     *\n",
      "    *                             *\n",
      "    *         235.6706            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error  9     *\n",
      "    *                             *\n",
      "    *         275.5472            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 10     *\n",
      "    *                             *\n",
      "    *         542.6152            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 11     *\n",
      "    *                             *\n",
      "    *         290.5143            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 12     *\n",
      "    *                             *\n",
      "    *         750.7367            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 13     *\n",
      "    *                             *\n",
      "    *         367.5540            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 14     *\n",
      "    *                             *\n",
      "    *         313.4105            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 15     *\n",
      "    *                             *\n",
      "    *         349.4554            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 16     *\n",
      "    *                             *\n",
      "    *         349.8203            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 17     *\n",
      "    *                             *\n",
      "    *         290.1820            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 18     *\n",
      "    *                             *\n",
      "    *         379.9805            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 19     *\n",
      "    *                             *\n",
      "    *         386.6198            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 20     *\n",
      "    *                             *\n",
      "    *         396.9621            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 21     *\n",
      "    *                             *\n",
      "    *         366.9122            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 22     *\n",
      "    *                             *\n",
      "    *         269.0095            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 23     *\n",
      "    *                             *\n",
      "    *         297.6357            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 24     *\n",
      "    *                             *\n",
      "    *         298.7431            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 25     *\n",
      "    *                             *\n",
      "    *         454.7715            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 26     *\n",
      "    *                             *\n",
      "    *         370.3972            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 27     *\n",
      "    *                             *\n",
      "    *         262.3211            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 28     *\n",
      "    *                             *\n",
      "    *         403.1871            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 29     *\n",
      "    *                             *\n",
      "    *         232.9431            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 30     *\n",
      "    *                             *\n",
      "    *         231.8510            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 31     *\n",
      "    *                             *\n",
      "    *         296.0335            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 32     *\n",
      "    *                             *\n",
      "    *         369.2642            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 33     *\n",
      "    *                             *\n",
      "    *         491.5897            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 34     *\n",
      "    *                             *\n",
      "    *         255.9886            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 35     *\n",
      "    *                             *\n",
      "    *         327.5583            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 36     *\n",
      "    *                             *\n",
      "    *         279.3829            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 37     *\n",
      "    *                             *\n",
      "    *         396.6794            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 38     *\n",
      "    *                             *\n",
      "    *         331.9764            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 39     *\n",
      "    *                             *\n",
      "    *         278.0145            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 40     *\n",
      "    *                             *\n",
      "    *         225.6361            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 41     *\n",
      "    *                             *\n",
      "    *         337.4393            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 42     *\n",
      "    *                             *\n",
      "    *         504.3356            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 43     *\n",
      "    *                             *\n",
      "    *         356.5840            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 44     *\n",
      "    *                             *\n",
      "    *         263.1881            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 45     *\n",
      "    *                             *\n",
      "    *         364.2544            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 46     *\n",
      "    *                             *\n",
      "    *         304.2363            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 47     *\n",
      "    *                             *\n",
      "    *         360.3100            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 48     *\n",
      "    *                             *\n",
      "    *         342.3312            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 49     *\n",
      "    *                             *\n",
      "    *         297.7306            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n",
      "\n",
      "    *******************************\n",
      "    *   Mean Squared Error 50     *\n",
      "    *                             *\n",
      "    *         350.6598            *\n",
      "    *                             *\n",
      "    *******************************\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print the list of MSE values for each iteration\n",
    "for i, mse in enumerate(normalized_mse_list):\n",
    "    mse_box = f\"\"\"\n",
    "    *******************************\n",
    "    *   Mean Squared Error {i+1:2d}     *\n",
    "    *                             *\n",
    "    *         {mse:.4f}            *\n",
    "    *                             *\n",
    "    *******************************\n",
    "    \"\"\"\n",
    "    print(mse_box)# Build and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838e5f28-1ec2-4e1d-ad91-e6a838f4db6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Normalized Mean Squared Errors: 344.0504\n",
      "Standard Deviation of Normalized Mean Squared Errors: 90.9970\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of the normalized MSE values\n",
    "mean_normalized_mse = np.mean(normalized_mse_list)\n",
    "std_normalized_mse = np.std(normalized_mse_list)\n",
    "\n",
    "# Report the results\n",
    "print(f\"Mean of Normalized Mean Squared Errors: {mean_normalized_mse:.4f}\")\n",
    "print(f\"Standard Deviation of Normalized Mean Squared Errors: {std_normalized_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec2b224-4a8e-489c-8b4c-568beec34879",
   "metadata": {},
   "source": [
    "## Comparison of Mean Squared Errors\n",
    "\n",
    "### Step A (Non-Normalized Data)\n",
    "- Mean of Mean Squared Errors: 198.8528\n",
    "- Standard Deviation of Mean Squared Errors: 361.5544\n",
    "\n",
    "### Step B (Normalized Data)\n",
    "- Mean of Normalized Mean Squared Errors: 344.0504\n",
    "- Standard Deviation of Normalized Mean Squared Errors: 90.9970\n",
    "\n",
    "The comparison between Step A and Step B shows that after normalizing the data, the mean squared errors have changed. The mean squared error is generally higher in the case of normalized data, indicating that the model's predictions have more variance from the actual values. The standard deviation of the mean squared errors is also lower for normalized data, suggesting that the spread of errors is less when the data is normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a36c058-aed2-499e-aa12-fd41cef1f974",
   "metadata": {},
   "source": [
    "## Part C: Increase Epochs and Comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "333958e3-578c-40c4-b79d-a686231521a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 268us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 273us/step\n",
      "10/10 [==============================] - 0s 263us/step\n",
      "10/10 [==============================] - 0s 270us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 264us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 261us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 270us/step\n",
      "10/10 [==============================] - 0s 256us/step\n",
      "10/10 [==============================] - 0s 256us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 258us/step\n",
      "10/10 [==============================] - 0s 278us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 299us/step\n",
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 270us/step\n",
      "10/10 [==============================] - 0s 263us/step\n",
      "10/10 [==============================] - 0s 284us/step\n",
      "10/10 [==============================] - 0s 282us/step\n",
      "10/10 [==============================] - 0s 262us/step\n",
      "10/10 [==============================] - 0s 273us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 270us/step\n",
      "10/10 [==============================] - 0s 268us/step\n",
      "10/10 [==============================] - 0s 265us/step\n",
      "10/10 [==============================] - 0s 272us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 261us/step\n",
      "10/10 [==============================] - 0s 266us/step\n",
      "10/10 [==============================] - 0s 267us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 274us/step\n",
      "10/10 [==============================] - 0s 268us/step\n",
      "10/10 [==============================] - 0s 273us/step\n",
      "10/10 [==============================] - 0s 270us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop(columns=['Strength'])\n",
    "y = df['Strength']\n",
    "\n",
    "# Create an empty list to store normalized MSE values\n",
    "normalized_mse_list_100_epochs = []\n",
    "\n",
    "# Repeat the process 50 times\n",
    "for _ in range(50):\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model with 100 epochs (suppress verbose output)\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the normalized MSE value\n",
    "    mse_normalized_100_epochs = mean_squared_error(y_test, predictions)\n",
    "    normalized_mse_list_100_epochs.append(mse_normalized_100_epochs)\n",
    "\n",
    "# Calculate the mean of the normalized MSE values for 100 epochs\n",
    "mean_normalized_mse_100_epochs = np.mean(normalized_mse_list_100_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd24447-d55d-4e47-b445-2ece054774d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Normalized Mean Squared Errors (50 Epochs): 344.0504\n",
      "Mean of Normalized Mean Squared Errors (100 Epochs): 157.6991\n"
     ]
    }
   ],
   "source": [
    "# Compare the mean squared errors\n",
    "print(f\"Mean of Normalized Mean Squared Errors (50 Epochs): {mean_normalized_mse:.4f}\")\n",
    "print(f\"Mean of Normalized Mean Squared Errors (100 Epochs): {mean_normalized_mse_100_epochs:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e217868-fab3-460b-aa51-ca72c5de3618",
   "metadata": {},
   "source": [
    "## Analysis of Mean Squared Errors with Different Epochs\n",
    "\n",
    "### Step B (50 Epochs)\n",
    "- Mean of Normalized Mean Squared Errors: 344.0504\n",
    "\n",
    "### Step C (100 Epochs)\n",
    "- Mean of Normalized Mean Squared Errors: 157.6991\n",
    "\n",
    "The comparison between Step B and Step C shows that increasing the number of epochs from 50 to 100 has significantly improved the mean squared error. The mean squared error decreased from 344.05044 to 157.6991, indicating that the model's predictions have become more accurate and closer to the actual values. This suggests that training the model for a greater number of epochs has helped it converge to a better solution, resulting in improved performance on the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49f5d9-8525-459f-ad35-e4a2f7be67cb",
   "metadata": {},
   "source": [
    "## Part D: Three Hidden Layers and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "318ac7ca-4a9e-489c-b86e-2b5703c9fd9c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 283us/step\n",
      "10/10 [==============================] - 0s 294us/step\n",
      "10/10 [==============================] - 0s 300us/step\n",
      "10/10 [==============================] - 0s 297us/step\n",
      "10/10 [==============================] - 0s 285us/step\n",
      "10/10 [==============================] - 0s 276us/step\n",
      "10/10 [==============================] - 0s 288us/step\n",
      "10/10 [==============================] - 0s 291us/step\n",
      "10/10 [==============================] - 0s 362us/step\n",
      "10/10 [==============================] - 0s 282us/step\n",
      "10/10 [==============================] - 0s 292us/step\n",
      "10/10 [==============================] - 0s 331us/step\n",
      "10/10 [==============================] - 0s 360us/step\n",
      "10/10 [==============================] - 0s 311us/step\n",
      "10/10 [==============================] - 0s 297us/step\n",
      "10/10 [==============================] - 0s 300us/step\n",
      "10/10 [==============================] - 0s 299us/step\n",
      "10/10 [==============================] - 0s 287us/step\n",
      "10/10 [==============================] - 0s 291us/step\n",
      "10/10 [==============================] - 0s 291us/step\n",
      "10/10 [==============================] - 0s 288us/step\n",
      "10/10 [==============================] - 0s 293us/step\n",
      "10/10 [==============================] - 0s 312us/step\n",
      "10/10 [==============================] - 0s 287us/step\n",
      "10/10 [==============================] - 0s 322us/step\n",
      "10/10 [==============================] - 0s 280us/step\n",
      "10/10 [==============================] - 0s 281us/step\n",
      "10/10 [==============================] - 0s 279us/step\n",
      "10/10 [==============================] - 0s 284us/step\n",
      "10/10 [==============================] - 0s 287us/step\n",
      "10/10 [==============================] - 0s 337us/step\n",
      "10/10 [==============================] - 0s 269us/step\n",
      "10/10 [==============================] - 0s 280us/step\n",
      "10/10 [==============================] - 0s 271us/step\n",
      "10/10 [==============================] - 0s 286us/step\n",
      "10/10 [==============================] - 0s 276us/step\n",
      "10/10 [==============================] - 0s 276us/step\n",
      "10/10 [==============================] - 0s 290us/step\n",
      "10/10 [==============================] - 0s 288us/step\n",
      "10/10 [==============================] - 0s 289us/step\n",
      "10/10 [==============================] - 0s 286us/step\n",
      "10/10 [==============================] - 0s 298us/step\n",
      "10/10 [==============================] - 0s 280us/step\n",
      "10/10 [==============================] - 0s 275us/step\n",
      "10/10 [==============================] - 0s 291us/step\n",
      "10/10 [==============================] - 0s 283us/step\n",
      "10/10 [==============================] - 0s 283us/step\n",
      "10/10 [==============================] - 0s 281us/step\n",
      "10/10 [==============================] - 0s 286us/step\n",
      "10/10 [==============================] - 0s 286us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an empty list to store normalized MSE values\n",
    "normalized_mse_list_three_layers = []\n",
    "\n",
    "\n",
    "# Repeat the process 50 times\n",
    "for _ in range(50):\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Build and compile the model with three hidden layers and ReLU activation\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model (suppress verbose output)\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the normalized MSE value\n",
    "    mse_normalized_three_layers = mean_squared_error(y_test, predictions)\n",
    "    normalized_mse_list_three_layers.append(mse_normalized_three_layers)\n",
    "\n",
    "# Calculate the mean of the normalized MSE values for three hidden layers\n",
    "mean_normalized_mse_three_layers = np.mean(normalized_mse_list_three_layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be96a184-c209-4cd3-b962-d8837d020ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Normalized Mean Squared Errors: 344.0504\n",
      "Mean of Normalized Mean Squared Errors (Three Layers): 126.8933\n"
     ]
    }
   ],
   "source": [
    "# Compare the mean squared errors\n",
    "print(f\"Mean of Normalized Mean Squared Errors: {mean_normalized_mse:.4f}\")\n",
    "print(f\"Mean of Normalized Mean Squared Errors (Three Layers): {mean_normalized_mse_three_layers:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d301a13e-398d-49fa-bdf0-f2139ba050d6",
   "metadata": {},
   "source": [
    "## Analysis of Mean Normalized Mean Squared Errors\n",
    "\n",
    "### Model with One Hidden Layer\n",
    "- Mean of Normalized Mean Squared Errors: 344.0504\n",
    "\n",
    "### Model with Three Hidden Layers\n",
    "- Mean of Normalized Mean Squared Errors: 126.8933\n",
    "\n",
    "The comparison between the model with one hidden layer and the model with three hidden layers reveals a substantial improvement in the mean normalized mean squared error. The mean squared error has significantly decreased from 345.9214 (one hidden layer) to 124.2107 (three hidden layers). This suggests that the neural network with three hidden layers is better at approximating the underlying patterns in the data, resulting in more accurate predictions on the test set. The additional hidden layers allow the model to capture more complex relationships within the data, leading to improved performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
